# -*- coding: utf-8 -*-
"""pattern_recognition_v1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d-_uY_nfZNgX8W6u5Xa1Nl0AuI3MZ_7E
"""

from PIL import Image
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import numpy as np
import tensorflow as tf

# load images
image_fw = cv2.imread("./drive/MyDrive/input_image/옷.png")
image_bg = cv2.imread("./drive/MyDrive/input_image/배경.png")
image_fw = cv2.resize(image_fw,(224, 224))
# cv2_imshow(image1)

image_bg = cv2.resize(image_bg,(224, 224))
difference = cv2.subtract(image_bg, image_fw)
image_fw[np.where((difference == [0,0,0]).all(axis=2))] = [0,0,0]
# cv2_imshow(image_fw)

input_image = tf.convert_to_tensor(image_fw, tf.dtypes.float32)
# print(input_image)
input_image = tf.expand_dims(input_image, 0)
# print(input_image)

interpreter = tf.lite.Interpreter(model_path = "/content/drive/MyDrive/model/pattern/model_unquant.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
print(input_shape)
interpreter.set_tensor(input_details[0]['index'], input_image)

interpreter.invoke()

labels = ["체크", "물방울", "꽃무늬", "기본", "스트라이프"]
output_data = interpreter.get_tensor(output_details[0]['index'])
# print(output_data)
print(labels[np.argmax(output_data)])